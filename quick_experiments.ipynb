{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ajm353/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from nltk.tokenize import word_tokenize \n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data/preprocessed/UBAR/multi-woz-processed/data_for_ubar.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10433"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 3409, 2: 5405, 3: 1619})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the distribution of the number of goals in each dialogue\n",
    "lens = []\n",
    "for i in range(len(df.columns)):\n",
    "    lens.append(len(df.iloc[0][i]))\n",
    "\n",
    "counts = Counter(lens)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexes of dialogues with 3 domains in multiwoz\n",
    "indices = [i for i, x in enumerate(lens) if x == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/raw/UBAR/multi-woz/data.json\"\n",
    "\n",
    "df_raw_mwoz = pd.read_json(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hotel': {'info': {'type': 'hotel',\n",
       "   'parking': 'yes',\n",
       "   'pricerange': 'cheap',\n",
       "   'internet': 'yes'},\n",
       "  'fail_info': {},\n",
       "  'book': {'pre_invalid': True,\n",
       "   'stay': '2',\n",
       "   'day': 'tuesday',\n",
       "   'invalid': False,\n",
       "   'people': '6'},\n",
       "  'fail_book': {'stay': '3'}}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_ten_goals = []\n",
    "for i in range(20):\n",
    "    parsed_goal = {}\n",
    "    goal = df_raw_mwoz.iloc[:,i].goal\n",
    "    for key in goal.keys():\n",
    "        relevant_goals = {k: v for k, v in goal.items() if v != {} and k != 'topic' and k != 'message'}\n",
    "        services = [key for key in relevant_goals.keys()]\n",
    "        for service in services:\n",
    "            parsed_goal[service] = relevant_goals[service]\n",
    "    first_ten_goals.append(parsed_goal)\n",
    "\n",
    "first_ten_goals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Save the system dialogue from all turns in all dialogues\n",
    "along with the turn number and the dialogue ID\n",
    "\"\"\"\n",
    "\n",
    "system_response_file = \"data/preprocessed/UBAR/system_responses.txt\"\n",
    "val_list_file = \"data/raw/UBAR/multi-woz/valListFile.json\"\n",
    "test_list_file = \"data/raw/UBAR/multi-woz/testListFile.json\"\n",
    "\n",
    "with open(val_list_file, 'r') as f:\n",
    "    val_list = f.readlines()\n",
    "    val_list = [x.strip() for x in val_list]\n",
    "\n",
    "with open(test_list_file, 'r') as f:\n",
    "    test_list = f.readlines()\n",
    "    test_list = [x.strip() for x in test_list]\n",
    "\n",
    "with open(system_response_file, 'w') as f:\n",
    "    f.write(\"Dialogue ID\\tTurn #\\tSystem Response\\n\")\n",
    "\n",
    "    for dialogue_idx, dialogue_filename in enumerate((df_raw_mwoz.columns)):\n",
    "        if dialogue_filename not in val_list and dialogue_filename not in test_list:\n",
    "            \n",
    "            for turn_idx in range(len(df_raw_mwoz.iloc[:,dialogue_idx].log)):\n",
    "                if turn_idx % 2 != 0:\n",
    "                    system_responses = df_raw_mwoz.iloc[:,dialogue_idx].log[turn_idx]['text']\n",
    "                    system_responses = system_responses.replace(\"\\n\", \" \")\n",
    "                    f.write(dialogue_filename + \"\\t\" + str(turn_idx) + \"\\t\" + system_responses + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUL2395.json is index 8\n",
      "PMUL4899.json is index 12\n",
      "PMUL3719.json is index 39\n"
     ]
    }
   ],
   "source": [
    "for idx, dialogue_name in enumerate(df_raw_mwoz.columns):\n",
    "    if dialogue_name == \"PMUL3719.json\":\n",
    "        print(\"PMUL3719.json is index \" + str(idx))\n",
    "    if dialogue_name == \"PMUL4899.json\":\n",
    "        print(\"PMUL4899.json is index \" + str(idx))\n",
    "    if dialogue_name == \"MUL2395.json\":\n",
    "        print(\"MUL2395.json is index \" + str(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Location based indexing can only have [integer, integer slice (START point is INCLUDED, END point is EXCLUDED), listlike of integers, boolean array] types",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py:769\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_tuple_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ajm353/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py?line=767'>768</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/ajm353/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py?line=768'>769</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_key(k, i)\n\u001b[1;32m    <a href='file:///home/ajm353/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py?line=769'>770</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py:1378\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ajm353/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py?line=1376'>1377</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/ajm353/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py?line=1377'>1378</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan only index by location with a [\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_valid_types\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Can only index by location with a [integer, integer slice (START point is INCLUDED, END point is EXCLUDED), listlike of integers, boolean array]",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ajm353/rds/rds-mlmi-2020-21-xyBFuSj0hm0/MLMI.2021-22/ajm353/Thesis/crazyneuraluser/quick_experiments.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhpc/home/ajm353/rds/rds-mlmi-2020-21-xyBFuSj0hm0/MLMI.2021-22/ajm353/Thesis/crazyneuraluser/quick_experiments.ipynb#ch0000009vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, dialogue_name \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(df_raw_mwoz\u001b[39m.\u001b[39mcolumns):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bhpc/home/ajm353/rds/rds-mlmi-2020-21-xyBFuSj0hm0/MLMI.2021-22/ajm353/Thesis/crazyneuraluser/quick_experiments.ipynb#ch0000009vscode-remote?line=1'>2</a>\u001b[0m     message \u001b[39m=\u001b[39m df_raw_mwoz\u001b[39m.\u001b[39;49miloc[:,dialogue_name]\u001b[39m.\u001b[39mgoal[\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py:961\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ajm353/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py?line=958'>959</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m    <a href='file:///home/ajm353/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py?line=959'>960</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[0;32m--> <a href='file:///home/ajm353/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py?line=960'>961</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[1;32m    <a href='file:///home/ajm353/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py?line=961'>962</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/ajm353/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py?line=962'>963</a>\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ajm353/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py?line=963'>964</a>\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py:1458\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   <a href='file:///home/ajm353/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py?line=1455'>1456</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_getitem_tuple\u001b[39m(\u001b[39mself\u001b[39m, tup: \u001b[39mtuple\u001b[39m):\n\u001b[0;32m-> <a href='file:///home/ajm353/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py?line=1457'>1458</a>\u001b[0m     tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_tuple_indexer(tup)\n\u001b[1;32m   <a href='file:///home/ajm353/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py?line=1458'>1459</a>\u001b[0m     \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   <a href='file:///home/ajm353/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py?line=1459'>1460</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_lowerdim(tup)\n",
      "File \u001b[0;32m~/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py:771\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_tuple_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ajm353/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py?line=768'>769</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(k, i)\n\u001b[1;32m    <a href='file:///home/ajm353/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py?line=769'>770</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> <a href='file:///home/ajm353/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py?line=770'>771</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/ajm353/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py?line=771'>772</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mLocation based indexing can only have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/ajm353/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py?line=772'>773</a>\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_valid_types\u001b[39m}\u001b[39;00m\u001b[39m] types\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/ajm353/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py?line=773'>774</a>\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ajm353/.conda/envs/crazyneuraluser/lib/python3.8/site-packages/pandas/core/indexing.py?line=774'>775</a>\u001b[0m \u001b[39mreturn\u001b[39;00m key\n",
      "\u001b[0;31mValueError\u001b[0m: Location based indexing can only have [integer, integer slice (START point is INCLUDED, END point is EXCLUDED), listlike of integers, boolean array] types"
     ]
    }
   ],
   "source": [
    "for idx, dialogue_name in enumerate(df_raw_mwoz.columns):\n",
    "    message = df_raw_mwoz.iloc[:,dialogue_name].goal[\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'restaurant']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['restaurant', 'train']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reorder the goals in the dialogue (goal_idx) to be aligned\n",
    "# with the order they are covered by the user utterances in the data\n",
    "\n",
    "import re\n",
    "\n",
    "goal_idx = 19\n",
    "\n",
    "current_dialogue_goals = []\n",
    "for idx, goal_name in enumerate(first_ten_goals[goal_idx]):\n",
    "    current_dialogue_goals.append(goal_name)\n",
    "\n",
    "print(current_dialogue_goals)\n",
    "\n",
    "\n",
    "message = df_raw_mwoz.iloc[:,goal_idx].goal[\"message\"]\n",
    "\n",
    "ordered_current_dialogue_goals = []\n",
    "\n",
    "for instruction in message:\n",
    "    instruction_split = re.split(\" |<|>\", instruction)\n",
    "    for word in instruction_split:\n",
    "        if word in current_dialogue_goals:\n",
    "            ordered_current_dialogue_goals.append(word)\n",
    "            current_dialogue_goals.remove(word)\n",
    "\n",
    "ordered_current_dialogue_goals\n",
    "# reorder first_ten_goals[goal_idx] to be aligned with ordered_current_dialogue_goals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLAIN BELOW CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read the user utterances from all turns in all dialogues in gen_usr_utterances_file and save them in \n",
    "the correct slots in new_data_file.\n",
    "\n",
    "# NOTE: this needs to be done for BOTH new_data_file AND new_data_file_with_spans as the first is used\n",
    "# by data_analysis.py and the second is used by preprocess.py to create the data_for_ubar.json file\n",
    "\"\"\"\n",
    "\n",
    "raw_data_file = \"data/raw/UBAR/multi-woz/data.json\"\n",
    "raw_data_file_with_spans = \"data/raw/UBAR/multi-woz/annotated_user_da_with_span_full.json\"\n",
    "new_data_file = \"data/preprocessed/UBAR/gen_usr_utt_experiment_data.json\"\n",
    "new_data_file_with_spans = \"data/preprocessed/UBAR/gen_usr_utt_experiment_data_with_span_full.json\"\n",
    "# Using file with duplicated data here to make sure that the data is not lost\n",
    "gen_usr_utterances_file = \"data/preprocessed/UBAR/duplicated_user_utterances_from_simulator.txt\"\n",
    "\n",
    "# Load the raw data to a df where the user utterances will be updated\n",
    "df_mwoz = pd.read_json(raw_data_file_with_spans)\n",
    "df_undedited_data = df_mwoz.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: ONLY RUN THIS FOR PROCESSING RAW_DATA_FILE AND NEW_DATA_FILE (no spans)\n",
    "\n",
    "# Read in gen_usr_utterances_file to a dictionary where the Dialogue ID is the key and the System Response is the value\n",
    "gen_usr_utterances_dict = {}\n",
    "with open(gen_usr_utterances_file, 'r') as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        line_split = line.split(\"\\t\")\n",
    "        dialogue_id = line_split[1]\n",
    "        system_response = line_split[3]\n",
    "        # Add the dialogue ID as the key to the dictionary with the System Response as the value\n",
    "        if line_split[1] in gen_usr_utterances_dict:\n",
    "            gen_usr_utterances_dict[dialogue_id].append(\" \".join(nltk.word_tokenize(system_response)))\n",
    "        else:\n",
    "            gen_usr_utterances_dict[dialogue_id] = [\" \".join(nltk.word_tokenize(system_response))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: ONLY RUN THIS FOR PROCESSING RAW_DATA_FILE_WITH_SPANS AND NEW_DATA_FILE_WITH_SPANS\n",
    "\n",
    "# Read in gen_usr_utterances_file to a dictionary where the Dialogue ID is the key and the System Response is the value\n",
    "gen_usr_utterances_dict = {}\n",
    "with open(gen_usr_utterances_file, 'r') as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        line_split = line.split(\"\\t\")\n",
    "        # Remove \".json\" from the end of the dialogue ID\n",
    "        dialogue_id = line_split[1].replace(\".json\", \"\")\n",
    "        system_response = line_split[3]\n",
    "        # Add the dialogue ID as the key to the dictionary with the System Response as the value\n",
    "        if dialogue_id in gen_usr_utterances_dict:\n",
    "            gen_usr_utterances_dict[dialogue_id].append(\" \".join(nltk.word_tokenize(system_response)))\n",
    "        else:\n",
    "            gen_usr_utterances_dict[dialogue_id] = [\" \".join(nltk.word_tokenize(system_response))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6537\n",
      "6537\n"
     ]
    }
   ],
   "source": [
    "# TEST SCRIPT #\n",
    "\n",
    "# Test the dialogues have been read into the dict correctly\n",
    "\n",
    "# Calculate the number of different Dialogue IDs in gen_usr_utterances_file\n",
    "dialogue_ids = {}\n",
    "with open(gen_usr_utterances_file, 'r') as f:\n",
    "    f.readline()\n",
    "    for line in f:\n",
    "        line_split = line.split(\"\\t\")\n",
    "        if line_split[1] not in dialogue_ids:\n",
    "            dialogue_ids[line_split[1]] = \"\"\n",
    "\n",
    "print(len(dialogue_ids))\n",
    "\n",
    "# Calculate the number of different Dialogue IDs in gen_usr_utterances_dict\n",
    "dialogue_ids = []\n",
    "for dialogue_id, user_utterances in gen_usr_utterances_dict.items():\n",
    "    dialogue_ids.append(dialogue_id)\n",
    "\n",
    "print(len(dialogue_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now need to update df_mwoz to *only* contain data from the dialogue IDs in gen_usr_utterances_dict\n",
    "# AND need to do some manipulation to handle the fact that the number of turns in the generated data\n",
    "# can be different to the raw data\n",
    "\n",
    "# If the dialogue ID is not in the gen_usr_utterances_dict, then remove the dialogue from df_mwoz\n",
    "for dialogue_id in df_mwoz.columns:\n",
    "    if dialogue_id not in gen_usr_utterances_dict.keys():\n",
    "        df_mwoz.drop(dialogue_id, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue ID not in df_mwoz: PMUL2245\n",
      "Dialogue ID not in df_mwoz: PMUL4859\n"
     ]
    }
   ],
   "source": [
    "# Deal with the cases where the number of generated turns is different to ground truth\n",
    "for dialogue_name, user_utterances in gen_usr_utterances_dict.items():\n",
    "    # This has to be done because there are dialogues not in \"annotated_user_da_with_span_full.json\" which\n",
    "    # must be due to an error when it was created\n",
    "    if dialogue_name not in df_mwoz.columns:\n",
    "        print(\"Dialogue ID not in df_mwoz: \" + dialogue_name)\n",
    "        continue\n",
    "    \n",
    "    dialogue_idx = df_mwoz.columns.get_loc(dialogue_name)\n",
    "    # Both of the below treat turns as total messages i.e. 6 turns is 3 user utterances and 3 sys responses\n",
    "    n_raw_turns = len(df_mwoz.iloc[:,dialogue_idx].log)\n",
    "    n_gen_sys_utt_turns = len(gen_usr_utterances_dict[dialogue_name]) * 2\n",
    "\n",
    "    # Case where the number of generated turns is less than the number of ground truth turns\n",
    "    if n_raw_turns > n_gen_sys_utt_turns:\n",
    "        turns_to_cut = n_raw_turns - n_gen_sys_utt_turns\n",
    "        # Remove the extra raw turns from the end of the dialogue, EXCEPT the last turn.\n",
    "        # This way, the final turn from the system is the actual final one in the raw data\n",
    "        # e.g. 'Thanks goobye' not some intermediary state where they might be asking the \n",
    "        # user a clarifying question or something like that\n",
    "        del df_mwoz.iloc[:,dialogue_idx].log[n_gen_sys_utt_turns - 1 : turns_to_cut + n_gen_sys_utt_turns - 1]\n",
    "\n",
    "    # Change the user utterances to the generated utterances up until all utterances are filled\n",
    "    # This handles the case where the number of generated utterances is greater than in the raw data\n",
    "    # which happens because of the user simulator always ends the conversation in my implementation\n",
    "    n_raw_turns = len(df_mwoz.iloc[:,dialogue_idx].log)\n",
    "    for usr_turn_idx, user_utterance in enumerate(user_utterances):  \n",
    "        turn_idx = usr_turn_idx * 2\n",
    "        if turn_idx < n_raw_turns: \n",
    "            df_mwoz.iloc[:,dialogue_idx].log[turn_idx]['text'] = user_utterance.strip('\\n')\n",
    "\n",
    "    # print(n_gen_sys_utt_turns, len(df_mwoz.iloc[:,dialogue_idx].log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6535"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST SCRIPT #\n",
    "\n",
    "# Calculate the new number of different Dialogue IDs in df_mwoz\n",
    "dialogue_ids = {}\n",
    "for dialogue_id in df_mwoz.columns:\n",
    "    if dialogue_id not in dialogue_ids:\n",
    "        dialogue_ids[dialogue_id] = \"\"\n",
    "\n",
    "len(dialogue_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue ID: PMUL4899.json\n",
      "******************************\n",
      "User: I am looking for entertainment in Cambridge .\n",
      "System: i got 5 options. which side is okay for you?\n",
      "User: I do n't care .\n",
      "System: How about funky fun house, they are located at 8 mercers row, mercers row industrial estate.\n",
      "User: That sounds great . Can I get the phone number and postcode ?\n",
      "System: Sure. The phone number is 01223304705, and the postcode is cb58hy. Is there anything else I can assist you with?\n",
      "User: Yes , I am also looking for an expensive Indian restaurant in the south .\n",
      "System: Trer are many. What kind of food would you like ?\n",
      "User: I would like Indian food .\n",
      "System: Unfortunately, there aren't any Indian restaurants in the south side of town, would you like me to look in other areas?\n",
      "User: No , I just need the address of one of the restaurants .\n",
      "System: I'm sorry there doesn't seem to be any expensive Indian restaurants to the south.\n",
      "User: Can you check again ? I just need the address .\n",
      "System: Please stop asking to check for the same thing. I have said there is none in the south try a different area.\n",
      "User: Can you check again ? I just need the address .\n",
      "System: Hi this is the supervisor. I apologize for the attitude of our staff. We do have taj tandoori, and expensive Indian restaurant in the South. Would you like me to book?\n",
      "User: No thank you . I just need the address .\n",
      "System: The address is 64 Cherry Hinton Road Cherry Hinton. Can i help you with anything else today?\n",
      "User: No , that 's all I need . Thank you .\n",
      "System: Have a great day. good bye.\n",
      "Dialogue ID: MUL2261.json\n",
      "******************************\n",
      "User: I am looking for a hotel called finches bed and breakfast .\n",
      "System: Yes! City Centre North B and B is an inexpensively-priced guesthouse in the north of town at 328A Histon Road. Would you like to book a room?\n",
      "User: Yes , please . I need it for 6 people and 4 nights starting from saturday .\n",
      "System: They weren't able to accommodate those parameters. Would you like to try a shorter stay?\n",
      "User: How about 2 nights ?\n",
      "System: The booking for City Centre North B&B has been made, your reference number is 0FAFY5PP.\n",
      "User: Thanks ! I also need a train from Bishops Stortford to Cambridge on Saturday .\n",
      "System: I can find one for you. Can you tell me what day you would like to travel, please? \n",
      "User: I would like to travel on Saturday and arrive by 14:45 .\n",
      "System: Great, I recommend train TR5108.  It departs at 13:29 and will get you there by 14:07.  Would you like me to book it?\n",
      "User: Yes , please book it for 6 people .\n",
      "System: Certainly! How many tickets would you like?\n",
      "User: I need 6 tickets .\n",
      "System: Booking was successful, the total fee is 48.48 GBP payable at the station .\n",
      "Reference number is : GSTIN0L6.\n",
      "User: Thank you so much for your help .\n",
      "System: You're welcome! Lovely day to you.\n"
     ]
    }
   ],
   "source": [
    "# TEST SCRIPT #\n",
    "\n",
    "# Inspect modified user utterances and system responses to sense check the updates\n",
    "\n",
    "for i in range(8, 10):\n",
    "    print(\"Dialogue ID: \" + df_mwoz.columns[i])\n",
    "    print(\"*\" * 30)\n",
    "    for j in range(len(df_mwoz.iloc[:,i].log)):\n",
    "        if j % 2 == 0:\n",
    "            print(\"User: \" + df_mwoz.iloc[:,i].log[j]['text'])\n",
    "        else:  \n",
    "            print(\"System: \" + df_mwoz.iloc[:,i].log[j]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the names of the new dialogues to avoid keys colliding when joining data\n",
    "\n",
    "for dialogue_id in df_mwoz.columns:\n",
    "    df_mwoz.rename(columns={dialogue_id: dialogue_id + \"_modified\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final step is to add the origal data into the df_mwoz which now contains only the new, generated data\n",
    "\n",
    "# Add df_undedited_data to df_mwoz\n",
    "joined_df_mwoz = df_mwoz.join(df_undedited_data, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df_raw_mwoz to new_data_file\n",
    "with open(new_data_file_with_spans, 'w') as f:\n",
    "    json.dump(joined_df_mwoz.to_dict(), f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIGURING OUT LENGTH DISPARITIES IN NUM TURNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of turns for each dialogue ID in df_raw_mwoz\n",
    "raw_data_dialogue_turn_counts = {}\n",
    "for idx, dialogue_name in enumerate(df_raw_mwoz.columns):\n",
    "    raw_data_dialogue_turn_counts[dialogue_name] = len(df_raw_mwoz.iloc[:,idx].log)\n",
    "\n",
    "# Count number of turns in each dialogue ID in data\n",
    "gen_dialogue_turn_counts = {}\n",
    "for dialogue_id in data.dialogue_id.unique():\n",
    "    gen_dialogue_turn_counts[dialogue_id] = len(data[data.dialogue_id == dialogue_id]) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated: SNG0129.json has 6 turns, but 10 turns in raw data\n",
      "generated: MUL2168.json has 18 turns, but 16 turns in raw data\n",
      "generated: SNG01445.json has 6 turns, but 8 turns in raw data\n",
      "generated: PMUL4899.json has 20 turns, but 22 turns in raw data\n",
      "generated: MUL0784.json has 16 turns, but 24 turns in raw data\n",
      "generated: SNG0548.json has 6 turns, but 8 turns in raw data\n",
      "generated: PMUL4372.json has 10 turns, but 16 turns in raw data\n",
      "generated: PMUL4047.json has 14 turns, but 16 turns in raw data\n",
      "generated: PMUL3552.json has 18 turns, but 26 turns in raw data\n",
      "generated: PMUL1539.json has 16 turns, but 18 turns in raw data\n",
      "generated: PMUL3296.json has 10 turns, but 12 turns in raw data\n",
      "generated: MUL1434.json has 14 turns, but 16 turns in raw data\n",
      "generated: SNG0297.json has 10 turns, but 8 turns in raw data\n",
      "generated: PMUL2049.json has 16 turns, but 18 turns in raw data\n",
      "generated: PMUL2749.json has 16 turns, but 18 turns in raw data\n",
      "generated: MUL1628.json has 14 turns, but 20 turns in raw data\n",
      "generated: PMUL1419.json has 12 turns, but 10 turns in raw data\n",
      "generated: SNG1197.json has 8 turns, but 6 turns in raw data\n",
      "generated: MUL2037.json has 14 turns, but 18 turns in raw data\n",
      "generated: MUL1497.json has 14 turns, but 20 turns in raw data\n",
      "generated: MUL0076.json has 24 turns, but 26 turns in raw data\n",
      "generated: PMUL3342.json has 8 turns, but 6 turns in raw data\n",
      "generated: MUL1113.json has 20 turns, but 22 turns in raw data\n",
      "generated: SNG0285.json has 14 turns, but 16 turns in raw data\n",
      "generated: SNG1134.json has 4 turns, but 6 turns in raw data\n",
      "generated: PMUL0608.json has 18 turns, but 20 turns in raw data\n",
      "generated: PMUL0621.json has 18 turns, but 22 turns in raw data\n",
      "generated: PMUL3299.json has 18 turns, but 24 turns in raw data\n",
      "generated: PMUL3486.json has 14 turns, but 12 turns in raw data\n",
      "generated: SNG0918.json has 4 turns, but 6 turns in raw data\n",
      "2444\n",
      "1896\n"
     ]
    }
   ],
   "source": [
    "# Go through gen_dialogue_turn_counts and compare whether the value for each key is the same\n",
    "# as the corresponding value in gen_dialogue_turn_counts\n",
    "count_fine = 0\n",
    "count_not_fine = 0\n",
    "for dialogue_id in gen_dialogue_turn_counts:\n",
    "    if gen_dialogue_turn_counts[dialogue_id] != raw_data_dialogue_turn_counts[dialogue_id]:\n",
    "        if count_not_fine < 30:\n",
    "            print(\"generated: \" + dialogue_id + \" has \" + str(gen_dialogue_turn_counts[dialogue_id]) + \" turns, but \" + str(raw_data_dialogue_turn_counts[dialogue_id]) + \" turns in raw data\")\n",
    "        count_not_fine += 1\n",
    "    else:\n",
    "        count_fine += 1\n",
    "print(count_fine)\n",
    "print(count_not_fine)\n",
    "        \n",
    "# Note that if the generated user utterances index is longer than the raw data then\n",
    "# it means the user answered a final time after the last system response \n",
    "# (beyond the data) because in the user model the user terminates it\n",
    "# But in UBAR the system terminates it\n",
    "# So in this case we just need to cut the final user utterance\n",
    "# from the generated user utterances i.e. not add it into the json file\n",
    "\n",
    "# In the case that the generated is shorter (often is)\n",
    "# It is usually just two turns shorter because \n",
    "# The dialogue system asks if they can help the user with anything else\n",
    "# And the user says no, but the user terminates the conversation beyond this point\n",
    "# So we can just throw these away. Same for bigger differences than 2, it\n",
    "# seems its just fluff we can throw away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I need a hotel with free wifi and free parking.\\n', 'metadata': {}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mwoz.iloc[:,0].log[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6b1dbda4ab90e582ad90c1a9c17ce386febb0de70284033ddca99cacd58ed69"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('crazyneuraluser')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
